package bda.tensorflow.nn.network;import bda.tensorflow.exception.LayerCreateException;import bda.tensorflow.exception.TensorflowRuntimeException;import bda.tensorflow.jni.*;import bda.tensorflow.jni_11.*;import bda.tensorflow.nn.CellFactory.RNNCellFactory;import bda.tensorflow.nn.Config;import bda.tensorflow.nn.LayerFactory.LayerFactory;import bda.tensorflow.nn.LayerInfo.*;import bda.tensorflow.run.Item;import bda.tensorflow.run.RNN.RNNMeta;import bda.tensorflow.util.Type;import bda.tensorflow.util.Util;import java.io.*;import java.lang.reflect.InvocationTargetException;import java.lang.reflect.Method;import java.net.URISyntaxException;import java.nio.ByteBuffer;import java.util.HashMap;import java.util.LinkedList;import java.util.List;import java.util.Map;import bda.tensorflow.nn.LayerFactory.RNNLayerFactory;import bda.tensorflow.nn.LayerFactory.BasicLayerFactory;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.FSDataInputStream;import org.apache.hadoop.fs.FileAlreadyExistsException;import org.apache.hadoop.fs.FileSystem;import org.apache.hadoop.fs.Path;import java.net.URI;import java.util.concurrent.ConcurrentHashMap;public class NetworkUtil {    static Map<Integer, RNNMeta> map = new ConcurrentHashMap<>();    static FileSystem fs = null;    static {        System.loadLibrary("jt");        //TODO:we must hardcode LayerFactory into this file. Change it when have better way        new RNNLayerFactory();        new BasicLayerFactory();    }//    this is real create//    public static RNNMeta create(int index, NetworkConfig network, RNNMeta meta) throws IllegalAccessException, TensorflowRuntimeException, InvocationTargetException {//        return network.graph.construct(index, network, meta, async);//    }    // This is for test!!!!!!!!!!!!!!    public static RNNMeta create(int index, NetworkConfig network, RNNMeta meta) throws TensorflowRuntimeException {        Scope scope = new Scope();        List<LayerInfo> layers = network.layer;        meta.shareNodeMap = new HashMap<>();        meta.variableMeta = new HashMap<>();        meta.varMap = new HashMap<>();        meta.items = new LinkedList<>();        meta.label = new LinkedList<>();        meta.variable = new LinkedList<>();        meta.data = new LinkedList<>();        Input[] x = new Input[network.inputSize];        for (int i = 0; i < network.inputSize; i++) {            x[i] = Operation.Placeholder(network.inputType, scope, Config.INPUT + i);            meta.data.add(x[i]);        }        Input[] y = new Input[network.outputSize];        for (int i = 0; i < network.outputSize; i++) {            y[i] = Operation.Placeholder(network.outputType, scope, Config.LABEL + i);            meta.label.add(y[i]);        }        meta.seq = Operation.Placeholder(Type.DT_FLOAT, scope, Config.SEQ);        int[] filter_sizes = new int[]{3, 4, 5};        Input[] nodeOuts = new Input[filter_sizes.length];        int i = 0;        int embedding_size = 300;        int num_filters = 3;        for (int filter_size : filter_sizes) {            String W_name = "W" + i;            String b_name = "b" + i;            int[] W_shape = new int[]{filter_size, embedding_size, 1, num_filters};            int[] b_shape = new int[]{num_filters};            int W_type = Type.DT_FLOAT;            int b_type = Type.DT_FLOAT;            Input w = RNNCellFactory.createNode(W_name, W_type, W_shape, meta, scope, network.appId, network.ps);            Input b = RNNCellFactory.createNode(b_name, b_type, b_shape, meta, scope, network.appId, network.ps);            Input input = Operation.ExpandDims(x[0], Operation.Const(new int[]{-1}, scope), scope);            Input conv = Operation.Conv2D(input, w, new int[]{1, 1, 1, 1}, "VALID", scope);            Input add = Operation.Add(conv, b, scope);            Input relu = Operation.Relu(add, scope);            Input pool = Operation.MaxPool(relu, new int[]{1, 56 - filter_size + 1, 1, 1},                    new int[]{1, 1, 1, 1}, "VALID", scope);            nodeOuts[i] = pool;            i += 1;        }        int num_filters_total = num_filters * filter_sizes.length;        Input pool = Operation.Concat(Operation.Const(3, scope), nodeOuts, scope);        Input pool_flat = Operation.Reshape(pool, Operation.Const(new int[]{-1, num_filters_total}, scope), scope);        int num_classes = 2;        String W_name = "W" + i;        String b_name = "b" + i;        int[] W_shape = new int[]{num_filters_total, num_classes};        int[] b_shape = new int[]{num_classes};        int W_type = Type.DT_FLOAT;        int b_type = Type.DT_FLOAT;        Input w = RNNCellFactory.createNode(W_name, W_type, W_shape, meta, scope, network.appId, network.ps);        Input b = RNNCellFactory.createNode(b_name, b_type, b_shape, meta, scope, network.appId, network.ps);        Input mul = Operation.MatMul(pool_flat, w, scope);        Input scores = Operation.Add(mul, b, scope);        Input losses = Operation.SparseSoftmaxCrossEntropyWithLogits(scores, y[0], scope);        Input w_loss = Operation.L2Loss(w, scope);        Input b_loss = Operation.L2Loss(b, scope);        Input mean_loss = Operation.Mean(losses, Operation.Const(new int[]{0}, scope), scope);        Input w_b_loss = Operation.Add(w_loss, b_loss, scope);        Input reg = Operation.Mul(w_b_loss, Operation.Const(new float[]{0.0f}, scope), scope);        Input loss = Operation.Add(mean_loss, reg, scope);        Input loss_identity = Operation.Identity(loss, scope);        Input loss_grad = Operation.Const(new float[]{1.0f}, scope);        meta.loss = loss_identity;        meta.lossgrad = loss_grad;        meta.scope = scope;        getGradient(meta);        addAssignNode(meta);        meta.lr = Operation.Placeholder(Type.DT_FLOAT, scope);        if (meta.async) {            meta.applys = new Input[meta.variable.size()];            for (int m = 0; m < meta.variable.size(); m++) {                Input v = meta.variable.get(m);                Input g = meta.gradient[m];                meta.applys[m] = Operation.ApplyGradientDescent(v, meta.lr, g, scope, true);            }        }        // add summary node//        Input[] summarys = new Input[meta.varMap.size()];//        int k = 0;//        for (Map.Entry<String, Input>  entry : meta.varMap.entrySet()) {//            summarys[k] = SummaryOperation.HistogramSummary(entry.getKey(), entry.getValue(), meta.scope);//            k += 1;//        }//        meta.summary = SummaryOperation.MergeSummary(summarys, scope);        Input predictions = Operation.ArgMax(scores, Operation.Const(1, scope), scope);        Input predictions_int32 = Operation.Cast(predictions, Type.DT_INT32, scope);        Input equal = Operation.Equal(predictions_int32, y[0], scope);        Input equal_float32 = Operation.Cast(equal, Type.DT_FLOAT, scope);        Input accuracy = Operation.Mean(equal_float32, Operation.Const(0, scope), scope);        meta.accu = accuracy;        meta.predict = new Input[]{predictions};        GraphDef def = new GraphDef();        Status status = new Status();        scope.toGraphDef(def, status);        meta.session.create(def);        if (network.master == null) {            meta.client = new ClientSession(scope, "");        } else {            int l = network.master.length;            //TODO: might exist better way? worth to explore            meta.client = new ClientSession(scope, network.master[index % l]);        }        return meta;    }//    public static RNNMeta create(int index, NetworkConfig network, RNNMeta meta) throws InvocationTargetException, IllegalAccessException, LayerCreateException, TensorflowRuntimeException {//        Scope scope = new Scope();//        List<LayerInfo> layers = network.layer;////        meta.shareNodeMap = new HashMap<>();//        meta.variableMeta = new HashMap<>();//        meta.varMap = new HashMap<>();////        meta.items = new LinkedList<>();//        meta.label = new LinkedList<>();//        meta.variable = new LinkedList<>();//        meta.data = new LinkedList<>();////        Input[] x = new Input[network.inputSize];//        for(int i = 0; i < network.inputSize; i++){//            x[i] = Operation.Placeholder(network.inputType, scope, Config.INPUT + i);//            meta.data.add(x[i]);//        }//        Input[] y = new Input[network.outputSize];//        for(int i = 0; i < network.outputSize; i++){//            y[i] = Operation.Placeholder(network.outputType, scope, Config.LABEL + i);//            meta.label.add(y[i]);//        }////        Input seq = null;//        if (network.isRNN) {//            seq = Operation.Placeholder(Type.DT_FLOAT, scope, Config.SEQ);//            meta.seq = seq;//        }////        LayerOutput output = new LayerOutput(x);//        GraphMetaInfo metaInfo = new GraphMetaInfo(scope, meta, network.batchSize, network.appId, network.ps);////        int len = network.layer.size();////        for (int i = 0; i < len; i++){//            LayerInfo info = layers.get(i);//            Method create = LayerFactory.getMethod(info.name);//            if (i != len-1) {//                LayerInput layerInput = info.input;//                layerInput.setInput(output);//                if (layerInput.needSeq()) {//                    layerInput.setSeq(seq);//                }////                output = (LayerOutput) create.invoke(LayerFactory.class, layerInput, metaInfo);//                meta.predict = output.output;//            } else {//                LossLayerInput layerInput = (LossLayerInput)info.input;//                layerInput.setInput(output);//                layerInput.y = y;////                //construct train graph//                output = (LayerOutput) create.invoke(LayerFactory.class, layerInput, metaInfo, false);//                LossLayerOutput lossOutput = (LossLayerOutput)output;//                meta.loss = lossOutput.loss;//                meta.lossgrad = lossOutput.lossgrad;//                meta.scope = scope;////                getGradient(meta);//                addAssignNode(meta);////                meta.lr = Operation.Placeholder(Type.DT_FLOAT, scope);////                if (async) {//                    for (int m = 0; m < meta.variable.size(); m++) {//                        Input v = meta.variable.get(m);//                        Input g = meta.gradient[m];//                        Operation.ApplyGradientDescent(v, meta.lr, g, scope, true);//                    }//                }////                output = (LayerOutput) create.invoke(LayerFactory.class, layerInput, metaInfo, true);//                GraphDef def = new GraphDef();//                Status status = new Status();//                scope.toGraphDef(def, status);//                assert (status.ok());//                meta.session.create(def);////                if(network.master == null) {//                    meta.client = new ClientSession(scope, "");//                } else {//                    int l = network.master.length;//                    //TODO: might exist better way? worth to explore//                    meta.client = new ClientSession(scope, network.master[index%l]);//                }//            }//        }////        return meta;//    }    public static void getGradient(RNNMeta meta) throws TensorflowRuntimeException {        Input[] variable = new Input[meta.variable.size()];        variable = meta.variable.toArray(variable);        meta.gradient = Operation.AddSymbolicGradients(meta.loss, meta.lossgrad, variable, meta.scope);    }    public static void addAssignNode(Map<String, Item> variableMeta, RNNMeta meta) {        for (Map.Entry<String, Item> entry : variableMeta.entrySet()) {            String variableName = entry.getKey();            int type = entry.getValue().type;            Util.addAssign(meta, variableName, type);        }    }    public static void addAssignNode(RNNMeta meta) {        int size = meta.variable.size();        meta.placeholder = new Input[size];        meta.assign = new Input[size];        for (int i = 0; i < meta.items.size(); i++) {            int type = meta.items.get(i).type;            Util.addAssign(meta, i, type);        }    }    public static void initGraph(int index, NetworkConfig network, RNNMeta meta)            throws IllegalAccessException, LayerCreateException, InvocationTargetException, NoSuchMethodException, TensorflowRuntimeException {        if (map.get(index) == null) {            create(index, network, meta);            map.put(index, meta);        }    }    public static void initGraph(int index, NetworkConfig network)            throws IllegalAccessException, LayerCreateException, InvocationTargetException, NoSuchMethodException, TensorflowRuntimeException {        if (map.get(index) == null) {            RNNMeta meta = new RNNMeta();            meta.async = network.async;            create(index, network, meta);            map.put(index, meta);        }    }    public static float[][] run(int index, Input[] inputs, Tensor[] tensors, Input[] outputs, NetworkConfig network) throws InvocationTargetException, LayerCreateException, TensorflowRuntimeException, NoSuchMethodException, IllegalAccessException {        initGraph(index, network);        RNNMeta meta = map.get(index);        Tensor[] output = new Tensor[outputs.length];        meta.client.run(inputs, tensors, outputs, output);        float[][] result = new float[outputs.length][];        for (int i = 0; i < output.length; i++) {            result[i] = output[i].toFloatArray();        }        return result;    }    public static float[][] run(int index, Input[] inputs, Tensor[] tensors, float[][] values, Input[] outputs, NetworkConfig network)            throws InvocationTargetException, LayerCreateException, TensorflowRuntimeException, NoSuchMethodException, IllegalAccessException {        initGraph(index, network);        RNNMeta meta = map.get(index);        List<Item> items = meta.items;        Input[] vars = new Input[meta.variable.size()];        meta.variable.toArray(vars);        Input[] input = new Input[inputs.length + vars.length];        Tensor[] tensor = new Tensor[inputs.length + vars.length];        System.arraycopy(inputs, 0, input, 0, inputs.length);        System.arraycopy(tensors, 0, tensor, 0, tensors.length);        System.arraycopy(vars, 0, input, inputs.length, vars.length);        for (int i = 0; i < values.length; i++) {            Tensor t = new Tensor(Type.DT_FLOAT, new TensorShape(items.get(i).shape));            t.initFromFloatArray(values[i]);            tensor[tensors.length + i] = t;        }        Tensor[] output = new Tensor[outputs.length];        System.out.println(index + " starts to run");        meta.client.run(input, tensor, outputs, output);        System.out.println(index + " run finish");        float[][] result = new float[outputs.length][];        for (int i = 0; i < output.length; i++) {            result[i] = output[i].toFloatArray();        }        System.out.println(index + " run finish, return");        return result;    }    public static void assignVariable(int index, NetworkConfig network, float[][] weight) throws InvocationTargetException, LayerCreateException, TensorflowRuntimeException, NoSuchMethodException, IllegalAccessException {        initGraph(index, network);        RNNMeta meta = map.get(index);        int size = meta.variable.size();        Tensor[] tensors = new Tensor[size];        List<Item> items = meta.items;        for (int i = 0; i < size; i++) {            Tensor t = new Tensor(Type.DT_FLOAT, new TensorShape(items.get(i).shape));            t.initFromFloatArray(weight[i]);            tensors[i] = t;        }        Tensor[] output = new Tensor[size];        meta.client.run(meta.placeholder, tensors, meta.assign, output);    }    public static Input getLr(int index, NetworkConfig network) throws InvocationTargetException, LayerCreateException, TensorflowRuntimeException, NoSuchMethodException, IllegalAccessException {        initGraph(index, network);        return map.get(index).lr;    }    public static Input[] getVariabe(int index, NetworkConfig network) throws InvocationTargetException, LayerCreateException, TensorflowRuntimeException, NoSuchMethodException, IllegalAccessException {        initGraph(index, network);        Input[] variable = new Input[map.get(index).variable.size()];        variable = map.get(index).variable.toArray(variable);        return variable;    }    public static Input[] getApply(int index, NetworkConfig network) throws InvocationTargetException, LayerCreateException, TensorflowRuntimeException, NoSuchMethodException, IllegalAccessException {        initGraph(index, network);        return map.get(index).applys;    }    public static Input getData(int index, int i, NetworkConfig network) throws InvocationTargetException, LayerCreateException, TensorflowRuntimeException, NoSuchMethodException, IllegalAccessException {        initGraph(index, network);//        if (i >= map.get(index).data.size())//            System.out.println("====================" + i + "====================");        return map.get(index).data.get(i);    }    public static Input getLabel(int index, int i, NetworkConfig network) throws InvocationTargetException, LayerCreateException, TensorflowRuntimeException, NoSuchMethodException, IllegalAccessException {        initGraph(index, network);        return map.get(index).label.get(i);    }    public static Input getSeq(int index, NetworkConfig network) throws InvocationTargetException, LayerCreateException, TensorflowRuntimeException, NoSuchMethodException, IllegalAccessException {        initGraph(index, network);        return map.get(index).seq;    }    public static Input[] getGradient(int index, NetworkConfig network) throws InvocationTargetException, LayerCreateException, TensorflowRuntimeException, NoSuchMethodException, IllegalAccessException {        initGraph(index, network);        return map.get(index).gradient;    }    public static Input getAccuracy(int index, NetworkConfig network) throws InvocationTargetException, LayerCreateException, TensorflowRuntimeException, NoSuchMethodException, IllegalAccessException {        initGraph(index, network);        return map.get(index).accu;    }    public static Input getLoss(int index, NetworkConfig network) throws InvocationTargetException, LayerCreateException, TensorflowRuntimeException, NoSuchMethodException, IllegalAccessException {        initGraph(index, network);        return map.get(index).loss;    }    public static Input[] getPredict(int index, NetworkConfig network) throws InvocationTargetException, LayerCreateException, TensorflowRuntimeException, NoSuchMethodException, IllegalAccessException {        initGraph(index, network);        return map.get(index).predict;    }    public static byte[] toByteArray(float[] array) {        int times = Float.SIZE / Byte.SIZE;        byte[] bytes = new byte[array.length * times];        for (int i = 0; i < array.length; i++) {            ByteBuffer.wrap(bytes, i * times, times).putFloat(array[i]);        }        return bytes;    }    public static float[] toFloatArray(byte[] byteArray) {        int times = Float.SIZE / Byte.SIZE;        float[] doubles = new float[byteArray.length / times];        for (int i = 0; i < doubles.length; i++) {            doubles[i] = ByteBuffer.wrap(byteArray, i * times, times).getFloat();        }        return doubles;    }    public static float[][] readFromHDFS(float[][] weight, String path) throws URISyntaxException, IOException {        if (fs == null)            fs = FileSystem.get(new URI("hdfs://10.61.1.119:9000"), new Configuration());        Path p = new Path(path);        InputStream in = fs.open(p);        float[][] w = new float[weight.length][];//        BufferedReader buff = new BufferedReader(new InputStreamReader(in));//        String str;        int l = "\n".getBytes().length;        for(int i = 0; i < weight.length; i++){            int len = (Float.SIZE / Byte.SIZE) * weight[i].length;            byte[] bytes = new byte[len];            in.read(bytes);            w[i] = toFloatArray(bytes);            bytes = new byte[l];            in.read(bytes);        }//        buff.close();        in.close();        return w;    }    public static void writeToHDFS(float[][] weight, String path) throws URISyntaxException, IOException {        if (fs == null)            fs = FileSystem.get(new URI("hdfs://10.61.1.119:9000"), new Configuration());        Path p = new Path(path);        try {            fs.createNewFile(p);            OutputStream out = fs.append(p);            for(float[] w : weight) {                out.write(toByteArray(w));                out.write("\n".getBytes());            }            out.flush();            out.close();        } catch (FileAlreadyExistsException e) {        }    }}